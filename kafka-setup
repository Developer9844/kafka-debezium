minikube config set memory 4096
minikube config set cpus 4
minikube start




kubectl create namespace kafka

helm upgrade --install kafka-release strimzi/strimzi-kafka-operator --namespace kafka --create-namespace
OR
kubectl create -f 'https://strimzi.io/install/latest?namespace=kafka' -n kafka

kubectl apply -f cluster.yml -n kafka

kubectl apply -f kafka_user2.yml -n kafka

kubectl get secret/test-kafka-user -n kafka -o yaml

kubectl get secret test-kafka-user -n kafka -o jsonpath='{.data.password}' | base64 --decode > user.password

kubectl get secret my-cluster-cluster-ca-cert -o jsonpath='{.data.ca\.crt}' -n kafka | base64 --decode > ca.p12

kubectl get secret my-cluster-cluster-ca-cert -o jsonpath='{.data.ca\.password}' -n kafka | base64 --decode > ca.password

kubectl -n kafka run kafka-producer -ti --image=quay.io/strimzi/kafka:0.38.0-kafka-3.6.0 --rm=true --restart=Never -- bin/kafka-console-producer.sh --bootstrap-server my-cluster-kafka-bootstrap:9092 --topic my-topic

kubectl -n kafka run kafka-consumer -ti --image=quay.io/strimzi/kafka:0.38.0-kafka-3.6.0 --rm=true --restart=Never -- bin/kafka-console-consumer.sh --bootstrap-server my-cluster-kafka-bootstrap:9092 --topic my-topic --from-beginning


kubectl cp ca.p12 kafka-producer:/tmp -n kafka
kubectl cp ca.p12 kafka-consumer:/tmp -n kafka

<<apply in both producer and consumer>>

cp $JAVA_HOME/lib/security/cacerts /tmp/cacerts

chmod 777 /tmp/cacerts

keytool -importcert -alias strimzi-kafka-cert -file /tmp/ca.p12 -keystore /tmp/cacerts -keypass <password from ca.password file> -storepass changeit -noprompt

<</>>

vim producer.properties #also create for consumer
>>

security.protocol=SASL_SSL
sasl.mechanism=SCRAM-SHA-512
sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="test-kafka-user" password="<password from user.password file>";
ssl.truststore.location=/tmp/cacerts
ssl.truststore.password=changeit

<<

kubectl cp producer.properties kafka-producer:/tmp -n kafka
kubectl cp consumer.properties kafka-consumer:/tmp -n kafka



#run the below command in kafka producer container
bin/kafka-console-producer.sh --bootstrap-server my-cluster-2-kafka-bootstrap:9092 --topic my-topic --producer.config /tmp/producer.properties
> type messages
> Hello

#run the below command in kafka consumer container
bin/kafka-console-consumer.sh --bootstrap-server my-cluster-kafka-bootstrap:9092 --topic my-topic --from-beginning
> Output
> Hello


get broker info:
kubectl describe kafka/my-cluster -n kafka

important link:
https://www.infoq.com/articles/strimzi-the-gitops-way/





cat <<EOF | kubectl -n postgres apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
 name: postgres-deployment-2
spec:
 selector:
   matchLabels:
     app: postgres-container-2
 template:
   metadata:
     labels:
       app: postgres-container-2
   spec:
     containers:
       - name: postgres-container-2
         image: debezium/example-postgres:1.0
         ports:
           - containerPort: 5432
         env:
           - name: POSTGRES_USER
             value: engineer
           - name: POSTGRES_PASSWORD
             value: password
---
apiVersion: v1
kind: Service
metadata:
 name: postgres-2
spec:
 ports:
   - port: 5432
 selector:
   app: postgres-container-2
EOF



*Install the strimzi operator:
# curl -L https://github.com/strimzi/strimzi-kafka-operator/releases/download/0.38.0/strimzi-cluster-operator-0.38.0.yaml | sed 's/namespace: .*/namespace: kafka/' | kubectl apply -f - -n kafka

*Create a single broker Kafka cluster:
# kubectl -n kafka apply -f https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/0.38.0/examples/kafka/kafka-persistent-single.yaml


*Create the KafkaConnect:

cat <<EOF | kubectl -n kafka apply -f -
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaConnect
metadata:
  name: postgres-connect-cluster
  annotations:
    strimzi.io/use-connector-resources: "false"
spec:
  image: ehsaniara/postgres-connect-debezium:latest
  replicas: 1
#  imagePullPolicy: Always
  bootstrapServers: my-cluster-kafka-bootstrap:9093
  tls:
    trustedCertificates:
      - secretName: my-cluster-cluster-ca-cert
        certificate: ca.crt
  config:
    config.storage.replication.factor: 1
    offset.storage.replication.factor: 1
    status.storage.replication.factor: 1
    config.providers: file
    config.providers.file.class: org.apache.kafka.common.config.provider.FileConfigProvider
EOF


*Create Postgres Connector:
once the Kafka Connect started you can run the following CURL command to create a connector to your Postgres database.

But, before that you should be able to access to the Kafka Connect through your local pc, so you need to run the following line:

# kubectl -n kafka port-forward svc/postgres-connect-cluster-connect-api 8083:8083



*then run the following command:
curl --location --request POST 'http://localhost:8083/connectors/' \
--header 'Accept: application/json' \
--header 'Content-Type: application/json' \
--data-raw '{
    "name": "sde-connector",
    "config": {
        "connector.class": "io.debezium.connector.postgresql.PostgresConnector",
        "database.hostname": "postgres.postgres",
        "database.port": "5432",
        "tasks.max": "1",
        "database.user": "data_engineer",
        "database.password": "password",
        "database.dbname": "data_engineer",
        "database.server.name": "server1",
        "database.history.kafka.bootstrap.servers": "my-cluster-kafka-bootstrap:9093",
        "database.history.kafka.topic": "schema-changes.inventory",
        "database.whitelist": "inventory",
        "include.schema.changes": true,
        "database.server.id": "184054"
    }
}'


---------------------------------------------------------------------------


apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaConnector
metadata:
 name: debezium-connector-mysql
 labels:
   strimzi.io/cluster: debezium-connect-cluster
spec:
 class: io.debezium.connector.mysql.MySqlConnector
 tasksMax: 1
 config:
   tasks.max: 1
   database.hostname: mysql
   database.port: 3306
   database.user: root
   database.password: alex
   database.server.id: 184054
   database.server.name: mysql
   database.include.list: moviesdb
   database.allowPublicKeyRetrieval: true
   table.include.list: moviesdb.OutboxEvent
   database.history.kafka.bootstrap.servers: my-cluster-kafka-bootstrap:9092
   database.history.kafka.topic: schema-changes.movies
   

   


curl --location --request POST 'http://localhost:8083/connectors/' \
--header 'Accept: application/json' \
--header 'Content-Type: application/json' \
--data-raw '{
    "name": "sde-connector",
    "config": {
        "tasks.max": "1",
        "connector.class": "io.debezium.connector.mysql.MySqlConnector",
        "database.port": "3306",
        "database.hostname": "mysql",
        "database.user": "root",
        "database.password": "alex",
        "database.server.id": "184054",
        "topic.prefix": "dbserver1",
        "database.server.name": "mysql",
        "database.include.list": "moviesdb",
        "database.allowPublicKeyRetrieval": "true",
        "table.include.list": "moviesdb.OutboxEvent",
        "database.history.kafka.bootstrap.servers": "my-cluster-kafka-bootstrap:9092",
        "database.history.kafka.topic": "schema-changes.movies",
        "schema.history.internal.kafka.bootstrap.servers": "my-cluster-kafka-bootstrap:9092",
        "schema.history.internal.kafka.topic": "schema-changes.movies"
    }
}'

        "connector.class": "io.debezium.connector.mysql.MySqlConnector",
        "tasks.max": "1",
        "database.hostname": "mysql",
        "database.port": "3306",
        "database.user": "debezium",
        "database.password": "dbz",
        "database.server.id": "184054",
        "topic.prefix": "dbserver1",
        "database.include.list": "inventory",
        "schema.history.internal.kafka.bootstrap.servers": "kafka:9092",
        "schema.history.internal.kafka.topic": "schema-changes.inventory"

   
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaConnect
metadata:
 name: debezium-connect-cluster
 annotations:
   strimzi.io/use-connector-resources: "true"
spec:
 version: 3.2.0
 image: quay.io/lordofthejars/debezium-connector-mysql:1.9.4
 replicas: 1
 bootstrapServers: my-cluster-kafka-bootstrap:9092
 config:
   group.id: connect-cluster
   key.converter: org.apache.kafka.connect.json.JsonConverter
   value.converter: org.apache.kafka.connect.json.JsonConverter
   key.converter.schemas.enable: false
   value.converter.schemas.enable: false
   offset.storage.topic: connect-offsets
   offset.storage.replication.factor: 1
   config.storage.topic: connect-configs
   config.storage.replication.factor: 1
   status.storage.topic: connect-status
   status.storage.replication.factor: 1